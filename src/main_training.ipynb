{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CSIRO Image2Biomass Prediction - Complete Solution\n",
    "Main training script implementing DINOv2, Tweedie Loss, and Hierarchical Constraints\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl # PyTorch Lightning for training loops used by DINOv2\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor # Callbacks for training monitoring and checkpointing the model\n",
    "from pytorch_lightning.loggers import WandbLogger # Weights & Biases logger for experiment tracking\n",
    "\n",
    "import timm # PyTorch Image Models library for DINOv2 model implementation\n",
    "import albumentations as A # Albumentations for data augmentation utilities used in training\n",
    "from albumentations.pytorch import ToTensorV2 # Convert images to PyTorch tensors that can be used in DataLoader\n",
    "from PIL import Image # Python Imaging Library for image processing tasks\n",
    "from sklearn.model_selection import GroupKFold # Group K-Fold cross-validation for splitting dataset into training and validation sets\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    # Paths\n",
    "    TRAIN_CSV = \"train.csv\"\n",
    "    TEST_CSV = \"test.csv\"\n",
    "    TRAIN_IMG_DIR = \"train\"\n",
    "    TEST_IMG_DIR = \"test\"\n",
    "    OUTPUT_DIR = \"outputs\"\n",
    "\n",
    "    # Model\n",
    "    BACKBONE = \"vit_small_patch14_dinov2.lvd142m\"  # DINOv2 Vision Transformer Small\n",
    "    IMG_SIZE = 518 # DINOv2 optimal input size \n",
    "    NUM_COMPONENTS = 5 # Number of biomass components to predict\n",
    "    HIDDEN_DIM = 512 # Hidden dimension for regression head\n",
    "    DROPOUT = 0.3 # Dropout rate for regression head\n",
    "\n",
    "    # Training\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_WORKERS = 4\n",
    "    MAX_EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4 \n",
    "    WEIGHT_DECAY = 1e-3 # Weight decay for optimizer\n",
    "    TWEEDIE_POWER = 1.5 # Tweedie loss power parameter\n",
    "\n",
    "    # Cross-validation\n",
    "    N_FOLDS = 5 # Number of folds for cross-validation\n",
    "    FOLD_TO_TRAIN = 0 # Specify which fold to train on\n",
    "\n",
    "    # Competition weights\n",
    "    TARGET_WEIGHTS = {\n",
    "        'Dry_Green_g': 0.1,\n",
    "        'Dry_Dead_g': 0.1,\n",
    "        'Dry_Clover_g': 0.1,\n",
    "        'GDM_g': 0.2,\n",
    "        'Dry_Total_g': 0.5\n",
    "    }\n",
    "\n",
    "    TARGET_NAMES = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def get_transforms(img_size: int, mode: str = 'train'):\n",
    "    \"\"\"Advanced augmentation pipeline for vegetation imagery\"\"\"\n",
    "\n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            A.RandomResizedCrop(\n",
    "                height=img_size, \n",
    "                width=img_size, \n",
    "                scale=(0.7, 1.0), \n",
    "                ratio=(0.9, 1.1), \n",
    "                p=1.0\n",
    "            ),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Transpose(p=0.5),\n",
    "\n",
    "            # Photometric (cautious with hue to avoid confusing green/dead)\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2, \n",
    "                contrast_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.RandomGamma(\n",
    "                gamma_limit=(80, 120), \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=10, \n",
    "                sat_shift_limit=20, \n",
    "                val_shift_limit=20, \n",
    "                p=0.3\n",
    "            ),\n",
    "\n",
    "            # Noise and regularization\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "            A.CoarseDropout(\n",
    "                max_holes=8,\n",
    "                max_height=32,\n",
    "                max_width=32,\n",
    "                fill_value=0,\n",
    "                p=0.3\n",
    "            ),\n",
    "\n",
    "            # Normalization (DINOv2 uses ImageNet stats)\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(height=img_size, width=img_size),\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"Dataset for CSIRO biomass prediction with pivoting from long to wide format\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, img_dir: str, transform=None, mode: str = 'train'):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == 'train':\n",
    "            # Pivot from long to wide format\n",
    "            self.df = df.pivot_table(\n",
    "                index=['image_path', 'Sampling_Date', 'State', 'Species', \n",
    "                       'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "                columns='target_name',\n",
    "                values='target'\n",
    "            ).reset_index()\n",
    "        \n",
    "            # Metadata normalization parameters\n",
    "            self.df['Height_Ave_cm'] = self.df['Height_Ave_cm'].fillna(0)\n",
    "            self.height_mean = self.df['Height_Ave_cm'].mean()\n",
    "            self.height_std = self.df['Height_Ave_cm'].std()\n",
    "\n",
    "            self.df['Pre_GSHH_NDVI'] = self.df['Pre_GSHH_NDVI'].fillna(0)\n",
    "            self.ndvi_mean = self.df['Pre_GSHH_NDVI'].mean()\n",
    "            self.ndvi_std = self.df['Pre_GSHH_NDVI'].std()\n",
    "        else:\n",
    "            # Test set: drop duplicates, keep unique images\n",
    "            self.df = df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        img_path = self.img_dir / row['image_path']\n",
    "        try:\n",
    "            image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            # Extract targets in correct order\n",
    "            targets = torch.tensor([\n",
    "                row['Dry_Green_g'],\n",
    "                row['Dry_Dead_g'],\n",
    "                row['Dry_Clover_g'],\n",
    "                row['GDM_g'],\n",
    "                row['Dry_Total_g']\n",
    "            ], dtype=torch.float32)\n",
    "\n",
    "            # Metadata features\n",
    "            date = pd.to_datetime(row['Sampling_Date'])\n",
    "            day_of_year = date.dayofyear\n",
    "            sin_date = np.sin(2 * np.pi * day_of_year / 365.0)\n",
    "            cos_date = np.cos(2 * np.pi * day_of_year / 365.0)\n",
    "\n",
    "            height_norm = (row['Height_Ave_cm'] - self.height_mean) / (self.height_std + 1e-6)\n",
    "            ndvi_norm = (row['Pre_GSHH_NDVI'] - self.ndvi_mean) / (self.ndvi_std + 1e-6)\n",
    "\n",
    "            meta = torch.tensor([sin_date, cos_date, height_norm, ndvi_norm], \n",
    "                               dtype=torch.float32)\n",
    "            \n",
    "            return image, meta, targets\n",
    "        else:\n",
    "            return image, str(row['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d623d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL COMPONENTS\n",
    "# ============================================================================\n",
    "class TweedieLoss(nn.Module):\n",
    "    \"\"\"Tweedie Loss for zero-inflated continuous data (1 < p < 2)\"\"\"\n",
    "\n",
    "    def __init__(self, p: float = 1.5, epsilon: float = 1e-8):\n",
    "        super().__init__()\n",
    "        assert 1 < p < 2, \"Tweedie power parameter p must be in (1, 2)\"\n",
    "        self.p = p\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        pred = pred + self.epsilon # Ensure numerical stability\n",
    "\n",
    "        # Tweedie deviance calculation\n",
    "        term1 = -target * torch.pow(pred, 1 - self.p) / (1 - self.p)\n",
    "        term2 = torch.pow(pred, 2 - self.p) / (2 - self.p)\n",
    "\n",
    "        loss = term1 + term2\n",
    "        return torch.mean(loss)\n",
    "\n",
    "class HierarchicalBiomassHead(nn.Module):    \n",
    "    \"\"\"\n",
    "    Ratio-constrained regression head ensuring sum(components) = total\n",
    "    Predicts total biomass + component ratios, then multiplies to get components\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim: int, num_components: int = 5, hidden_dim: int = 512):\n",
    "        super().__init__()\n",
    "        self.num_components = num_components\n",
    "\n",
    "        # Common feature extractor\n",
    "        self.common = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        # Total biomass branch (scalar output)\n",
    "        self.total_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "            nn.Softplus()  # Ensure positive output \n",
    "        )\n",
    "\n",
    "        # Component ratio branch (vector output)\n",
    "        self.ratio_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_components),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        feat = self.common(x) # Shared feature extraction\n",
    "\n",
    "        # Predict total biomass\n",
    "        total_biomass = self.total_head(feat) # (batch, 1)\n",
    "\n",
    "        # Predict component ratios\n",
    "        ratio_logits = self.ratio_head(feat) # (batch, num_components) \n",
    "        ratios = F.softmax(ratio_logits, dim=1) # (batch, num_components), sum to 1\n",
    "\n",
    "        # Derive component biomass\n",
    "        component_biomass = total_biomass * ratios # (batch, num_components)\n",
    "\n",
    "        return component_biomass, total_biomass, ratios\n",
    "    \n",
    "class DinoBiomassModel(pl.LightningModule):\n",
    "    \"\"\"Main model with DINOv2 backbone and hierarchical constraints\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.config = config\n",
    "\n",
    "        # Load DINOv2 backbone\n",
    "        self.backbone = timm.create_model(\n",
    "            config.BACKBONE,\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # No/Remove classification head\n",
    "        )\n",
    "\n",
    "        self.embed_dim = self.backbone.num_features\n",
    "\n",
    "        # Freeze early layers of backbone (layer-wise freezing strategy)\n",
    "        self._freeze_backbone_layers()\n",
    "\n",
    "        # Hierarchical regression head\n",
    "        self.head = HierarchicalBiomassHead(\n",
    "            in_dim=self.embed_dim,\n",
    "            num_components=config.NUM_COMPONENTS,\n",
    "            hidden_dim=config.HIDDEN_DIM\n",
    "        )\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = TweedieLoss(p=config.TWEEDIE_POWER)\n",
    "\n",
    "        # Competition weights\n",
    "        self.register_buffer('weights', torch.tensor([\n",
    "            config.TARGET_WEIGHTS['Dry_Green_g'],\n",
    "            config.TARGET_WEIGHTS['Dry_Dead_g'],\n",
    "            config.TARGET_WEIGHTS['Dry_Clover_g'],\n",
    "            config.TARGET_WEIGHTS['GDM_g'],\n",
    "            config.TARGET_WEIGHTS['Dry_Total_g']\n",
    "        ]))\n",
    "\n",
    "        # Metrics storage\n",
    "        self.validation_step_outputs = []\n",
    "    \n",
    "    def _freeze_backbone_layers(self):\n",
    "        \"\"\"Freeze patch embedding and early transformer blocks\"\"\"\n",
    "\n",
    "        # Freeze all parameters first\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze last 2-3 blocks for fine-tuning\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            # For ViT-Small (12 blocks), unfreeze blocks 10-11\n",
    "            if any(x in name for x in ['blocks.10', 'blocks.11', 'norm']):\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # DINOv2 feature extraction\n",
    "        features = self.backbone(x)  # (batch, embed_dim)\n",
    "\n",
    "        # Hierarchical regression head\n",
    "        components, total_pred, ratios = self.head(features)  # (batch, num_components), (batch, 1), (batch, num_components)\n",
    "\n",
    "        return components, total_pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, meta, targets = batch\n",
    "\n",
    "        # Forward pass\n",
    "        preds, total_pred = self(images)\n",
    "\n",
    "        # Weighted Tweedie loss\n",
    "        loss = 0\n",
    "        for i in range(self.config.NUM_COMPONENTS):\n",
    "            component_loss = self.criterion(preds[:, i], targets[:, i])\n",
    "            loss += component_loss * self.weights[i]\n",
    "        \n",
    "        # Logging\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, meta, targets = batch\n",
    "        preds, total_pred = self(images)\n",
    "\n",
    "        # Weighted Tweedie loss\n",
    "        loss = 0\n",
    "        for i in range(self.config.NUM_COMPONENTS):\n",
    "            component_loss = self.criterion(preds[:, i], targets[:, i])\n",
    "            loss += component_loss * self.weights[i]\n",
    "        \n",
    "        # MSE for monitoring\n",
    "        mse_loss = F.mse_loss(preds, targets)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_mse', mse_loss, prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        # Store predictions for R² calculation\n",
    "        self.validation_step_outputs.append({\n",
    "            'preds': preds.detach().cpu(),\n",
    "            'targets': targets.detach().cpu()\n",
    "        })\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate weighted R² at end of validation epoch\"\"\"\n",
    "        all_preds = torch.cat([x['preds'] for x in self.validation_step_outputs], dim=0)\n",
    "        all_targets = torch.cat([x['targets'] for x in self.validation_step_outputs], dim=0)\n",
    "\n",
    "        # Compute weighted R²\n",
    "        # Calculate weighted R²\n",
    "        r2_score = self._calculate_weighted_r2(all_preds, all_targets)\n",
    "        self.log('val_r2', r2_score, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def _calculate_weighted_r2(self, preds: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "        \"\"\"Calculate globally weighted R² as per competition metric\"\"\"\n",
    "        # Flatten and apply weights\n",
    "        preds_flat = preds.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        weights_expanded = self.weights.repeat(preds.size(0))\n",
    "\n",
    "        # Weighted mean\n",
    "        weighted_mean = (weights_expanded * targets_flat).sum() / weights_expanded.sum()\n",
    "\n",
    "        # Weighted SS_res and SS_tot\n",
    "        ss_res = (weights_expanded * (targets_flat - preds_flat) ** 2).sum()\n",
    "        ss_tot = (weights_expanded * (targets_flat - weighted_mean) ** 2).sum()\n",
    "        \n",
    "        r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
    "        return r2.item()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, self.parameters()),\n",
    "            lr=self.config.LEARNING_RATE,\n",
    "            weight_decay=self.config.WEIGHT_DECAY\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cac57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING PIPELINE\n",
    "# ============================================================================\n",
    "def prepare_data(config: Config):\n",
    "    \"\"\"Load and prepare data with stratified group K-Fold splitting\"\"\"\n",
    "    train_df  = pd.read_csv(config.TRAIN_CSV)\n",
    "\n",
    "    # Create groups based on location/date to prevent data leakage\n",
    "    train_df['group'] = train_df['image_path'].str.extract(r'(ID\\d+)')[0]\n",
    "\n",
    "    # Stratify by total biomass bins\n",
    "    train_df_pivot = train_df.pivot_table(\n",
    "        index=['image_path', 'group'],\n",
    "        columns='target_name',\n",
    "        values='target'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Create biomass bins for stratification\n",
    "    total_biomass = train_df_pivot['Dry_Total_g']\n",
    "    train_df_pivot['biomass_bin'] = pd.qcut(total_biomass, q=5, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Group K-Fold\n",
    "    gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "    train_df_pivot['fold'] = -1\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(\n",
    "        train_df_pivot,\n",
    "        train_df_pivot['biomass_bin'],\n",
    "        groups=train_df_pivot['group']\n",
    "    )):\n",
    "        train_df_pivot.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "    # Merge fold info back to original dataframe\n",
    "    fold_map = dict(zip(train_df_pivot['image_path'], train_df_pivot['fold']))\n",
    "    train_df['fold'] = train_df['image_path'].map(fold_map)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def train_fold(train_df: pd.DataFrame, fold: int, config: Config):\n",
    "    \"\"\"Train a single fold\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Fold {fold}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Split data\n",
    "    train_fold_df = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_fold_df = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Train samples: {len(train_fold_df)}\")\n",
    "    print(f\"Val samples: {len(val_fold_df)}\")\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = BiomassDataset(\n",
    "        train_fold_df,\n",
    "        config.TRAIN_IMG_DIR,\n",
    "        transform=get_transforms(config.IMG_SIZE, mode='train'),\n",
    "        mode='train'\n",
    "    )\n",
    "\n",
    "    val_dataset = BiomassDataset(\n",
    "        val_fold_df,\n",
    "        config.TRAIN_IMG_DIR,\n",
    "        transform=get_transforms(config.IMG_SIZE, mode='val'),\n",
    "        mode='train'\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = DinoBiomassModel(config)\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"{config.OUTPUT_DIR}/fold_{fold}\",\n",
    "        filename=\"best-{epoch:02d}-{val_r2:.4f}\",\n",
    "        monitor=\"val_r2\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=1,\n",
    "    )\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_r2',\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.MAX_EPOCHS,\n",
    "        accelerator='auto',\n",
    "        devices='auto',\n",
    "        precision='16-mixed',\n",
    "        callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "        log_every_n_steps=10,\n",
    "        deterministic=False\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    return checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INFERENCE\n",
    "# ============================================================================\n",
    "def predict(model_path: str, config: Config):\n",
    "    \"\"\"Generate predictions for test set\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Generating Predictions\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Load model\n",
    "    model = DinoBiomassModel.load_from_checkpoint(model_path, config=config)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(config.TEST_CSV)\n",
    "    test_dataset = BiomassDataset(\n",
    "        test_df,\n",
    "        config.TEST_IMG_DIR,\n",
    "        transform=get_transforms(config.IMG_SIZE, mode='val'),\n",
    "        mode='test'\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    predictions = []\n",
    "    image_paths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, paths in test_loader:\n",
    "            images = images.cuda()\n",
    "            preds, _ = model(images)\n",
    "            predictions.append(preds.cpu().numpy())\n",
    "            image_paths.extend(paths)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "\n",
    "    # Create submission DataFrame\n",
    "    submission_rows = []\n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        img_id = Path(img_path).stem\n",
    "        for i, target_name in enumerate(config.TARGET_NAMES):\n",
    "            sample_id = f\"{img_id}__{target_name}\"\n",
    "            target_value = predictions[idx, i]\n",
    "            submission_rows.append({\n",
    "                'sample_id': sample_id,\n",
    "                'target': target_value\n",
    "            })\n",
    "    \n",
    "    submission_df = pd.DataFrame(submission_rows)\n",
    "    submission_df.to_csv(f\"{config.OUTPUT_DIR}/submission.csv\", index=False)\n",
    "    print(f\"Submission saved to {config.OUTPUT_DIR}/submission.csv\")\n",
    "\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Prepare data\n",
    "    train_df = prepare_data(config)\n",
    "    \n",
    "    # Train\n",
    "    if config.FOLD_TO_TRAIN is not None:\n",
    "        # Train single fold\n",
    "        best_model_path = train_fold(train_df, config.FOLD_TO_TRAIN, config)\n",
    "        # Generate predictions\n",
    "        predict(best_model_path, config)\n",
    "    else:\n",
    "        # Train all folds\n",
    "        best_models = []\n",
    "        for fold in range(config.N_FOLDS):\n",
    "            best_model_path = train_fold(train_df, fold, config)\n",
    "            best_models.append(best_model_path)\n",
    "        \n",
    "        print(\"\\nAll folds trained. Best models:\")\n",
    "        for i, path in enumerate(best_models):\n",
    "            print(f\"Fold {i}: {path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
